\documentclass[11pt]{article}
\usepackage{times}

\setlength{\textwidth}{6.5in}
\setlength{\textheight}{9.0in}
\setlength{\topmargin}{-.5in}
\setlength{\oddsidemargin}{-.0600in}
\setlength{\evensidemargin}{.0625in}

\newcommand{\secref}[1]{Section~\ref{#1}}



%\newcommand{\doublespace}{\baselineskip0.34truein}
%\newcommand{\singlespace}{\baselineskip0.16truein}
%\newcommand{\midspace}{\baselineskip0.24truein}
%\newcommand{\midplusspace}{\baselineskip0.26truein}

\title{\bf Campus Grids}

\usepackage{setspace}
\usepackage{algorithmic}
\usepackage{algorithm}

\usepackage{graphicx}
\usepackage{calc}
\usepackage{url}

\newlength{\imgwidth}

\newcommand\scalegraphics[1]{%   
    \settowidth{\imgwidth}{\includegraphics{#1}}%
    \setlength{\imgwidth}{\minof{\imgwidth}{\textwidth}}%
    \includegraphics[width=\imgwidth]{#1}%
}



\doublespacing

\author{Derek Weitzel\\
Computer Science and Engineering\\
University of Nebraska--Lincoln\\
Lincoln, NE 66588-0115\\
dweitzel@cse.unl.edu
       }
       
\begin{document}

\maketitle

\begin{abstract}

At many universities, each department maintains a independent cluster for their researchers.  Many of these clusters are under utilized while researchers at other departments may require these resources.  Linking these clusters with traditional grid software would require changes in security and execution environments.  In this paper we will describe a framework and technology that are used to link departmental clusters such that submission at one cluster could lead to execution on another.  This framework is then further expanded to operating on a national production grid.  Additionally, the framework is designed as lightweight, and leveraging existing security infrastructure.   All of these components are functional and are running research jobs in production.

\end{abstract}

%   \tableofcontents
%   \newpage

% \doublespace

\section{Introduction}
\label{sec:Introduction}

\subsubsection* {The problem we have solved}

\begin{itemize}
%\item
%Concentrate on making {\em this} assertion and {\em only} this assertion in a
%succinct set of 1 to 3 paragraphs 

\item Department clusters waste power by being under utilized for significant portions of time.
\item Researchers have peaks in usage and need overflow capacity.
\item Move single core jobs around to idle clusters, freeing up space for MPI jobs.
\item Users want a single execution environment.  This is an expressed goal of the Condor project.
\item Increased utilization of a cluster can reflect well on the department.
\item Use existing security infrastructure.

%\item
%A common mistake is to explain too much of the problem context first. Instead,
%state the problem essentially as a claim, and leave explanations supporting
%your claim to the next part, ``Why it is not already solved.''

\end{itemize}

As the speed of innovation in computing increases, it is common for a campus to have multiple generations of clusters.  These clusters are commonly bought as independent systems, not meant to share work between them.  This causes users to flock to the newest generation hardware, hoping to increase the performance of their application.  This movement of users leads to under utilization of older hardware, and increased demand on the newest.

This is just one of many situations that would cause users to underutilize hardware.  Other situations could be:

\begin{itemize}
\item \textbf{Departmental clusters:}  Each department has a dedicated cluster.  This cluster specialization can cause under utilization when department researchers are not using the resources.
\item \textbf{Peaks of usage:} In general, users have peaks to their usage around deadlines.
\item \textbf{Parallel jobs:} While a cluster is draining nodes for a large parallel job, the cluster could fill those drained slots with pre-emptable usage.
\end{itemize}

One way to alleviate this demand is to move single core jobs to other clusters that have idle cycles.  Recently, the single core performance has been stagnant, therefore moving the single core jobs to the older hardware will not significantly decrease performance.  Also, by moving the single core jobs, it can free the newest hardware for large parallel jobs which can benefit from better interconnects, larger and faster storage, and increased core count that are on the newest hardware.




\subsubsection* {Why the problem is not already solved or other solutions 
are ineffective in one or more important ways}


%\item
%Your new idea need not solve every problem but it should solve at least one
%that is not already solved

There have been several attempts to create a distributed campus grid.  They all use some technology to distribute and schedule the jobs on the grid.  Some methods for distribution are commercial such as Moab.  Others are translation layers between a generic description language and a scheduler, such as Globus.  Still others are entire resource managers and schedulers like Condor.  Each of these solutions can be built to create a campus grid, but they all have drawbacks that are highlighted below.

One solution to build a grid is to use a single vendor/software solution.  For example, Cluster Resources offer a solution Moab Grid Suite\cite{website:moabgrid}.  This solution requires each resource to run a single piece of proprietary software, Moab.  Moab is a meta-scheduler, using PBS to manage the underlying resources.  Moab is a expensive By using Moab, the development of new grid technologies are limited to what can be done in Moab.

Placing Globus gatekeepers on each cluster would allow jobs to be submitted to each cluster without modifying the underlying batch system.  But, this would require a higher layer of abstraction over the Globus gatekeepers to optimally balance load between clusters.  Additionally, Globus has well known limitations such as job a low submission rate, and high resource usage.  Globus implements security that is inconstant with most existing campus security architectures.  Also, it does not provide a method for transparent execution on other clusters, which experience on the OSG has shown is important to users.

Another single vendor solution is Condor.  Each resource can run Condor on their clusters and 'flock' \cite{epema1996worldwide} to each other.  In this solution, jobs would be balanced on each resource due to Condor's greedy scheduler algorithm.  But, this again requires each resource to run Condor as their scheduler and resource manager.  Additionally, Condor must be running on each worker node, increasing the administration requirements.  This suffers from the same problem as Moab, restricting further innovation to the confines of a single solution.



In each of these cases, we used technology

%\item 
%A common solution to linking clusters is condor flocking.  Flocking requires every cluster to run condor daemons on their nodes.  

% Last case, since it's simalar to mine.
%Several universities have approached the problem utilizing condor flocking.

%\item
%This is the place to provide a succinct description of the problem context
%giving enough information to support the claim that a problem exists, made in
%the preceding problem declaration.





\subsubsection* {Why our solution is worth considering and why is it effective
in some way that others are not}

\begin{itemize}
%\item
%A succinct statement of {\em why} the reader should care enough to read the
%rest of the paper.
\item The framework described in this paper is designed as a modular framework that will allow clusters to overflow onto each other and to the grid.  This framework requires running condor on only one node in the cluster.  Each job that comes from another cluster will go through the default scheduler, whether it's PBS, SGE, or LSF.

%\item
%This should include a statement about the characteristics of your solution to
%the problem which 1) make it a solution, and 2) make it superior to other
%solutions to the same problem.

\end{itemize}


\subsubsection* {How the rest of the paper is structured}


The rest of this paper first discusses related work in
\secref{sec:RelatedWork}, and then describes our implementation in
\secref{sec:Implementation}. \secref{sec:Evaluation} describes how we evaluated
our system and presents the results. \secref{sec:Conclusion} presents our
conclusions and describes future work.


\section{Related Work}
\label{sec:RelatedWork}

\subsubsection*{Other efforts that exist to solve this problem and why are they
less effective than our method}

\begin{itemize}
%\item
%Resist the urge to point out only flaws in other work. Do your best to point
%out both the strengths and weaknesses to provide as well rounded a view of how
%your idea relates to other work as possible
\item
Globus is a translation layer between the (globus specific?) Resource Specification Language, and the local resource manager.  It has been very successful in that is has a large install base.  Globus also has deep integration with standard grid credentials such as PKI.

\item
Condor Flocking

\item
Virginia Campus Grid \cite{humphrey2005university}.  They used globus 4 WSRF to create a grid.  They used the campus information services and authentication methods.  They do not mention load balancing or brokering.

\item
Oxford Campus Grid \cite{wallom2006oxgrid}.  Oxford leveraged the VDT stack, and Condor-G.  They built an equivalent of OSGMM using Condor-G and GLUE attributes to submit to globus gatekeepers installed on the clusters.  So, they built an OSG.

%\item
%In a social and political sense, it is {\em very smart} as well as ethical to
%say good things, which are true, about other people's work. A major motivation
%for this is that editors and program committee members have to get a set of
%reviews for your paper. The easiest way for them to decide who should review it
%is to look at the set of references to {\em related work} (e.g.,
%\cite{ARJ:95,BHR:90,Go:97}) to find people who are likely to be competent to
%review your paper.  The people whose work you talk about are thus likely to be
%reading what you say about {\em their} work while deciding what to say about
%{\em your} work. 

%\item
%Clear enough? Speak the truth, say what you have to say, but be generous to the
%efforts of others.

\end{itemize}


\subsubsection*{Other efforts that exist to solve related problems that are
relevant, how are they relevant, and why are they less effective than our
solution for this problem}

\begin{itemize}

\item
Diagrid

\item 
GlideinWMS

\item
Panda

%\item 
%Many times no one has solved your exact problem before, but others have solved
%closely related problems or problems with aspects that are strongly analogous
%to aspects of your problem

\end{itemize}

\section{Implementation}
\label{sec:Implementation}

\subsubsection*{What we (will do $|$ did): {\em Our Solution}}
\begin{itemize}

%\item   Another way to look at this section is as a paper, within a paper,
%describing your implementation. That viewpoint makes this the introduction to
%the subordinate paper, which should describe the overall structure of your
%implementation and how it is designed to address the problem effectively.

%\item   Then, describe the structure of the rest of this section, and what each
%subsection describes.

\item
Created a campus grid integrating 3 clusters on a campus into a grid.  Submission to any of the clusters could overflow to the other 2.

\item
Overflow to the grid

\item
Using offline ads to efficiently match jobs to glideins on the non-condor cluster.

\end{itemize}



\subsubsection*{How our solution (will $|$ does) work}
%\begin{itemize}
%\item   This is the body of the subordinate paper describing your solution. It
%may be divided into several subsections as required by the nature of your
%implementation.

%\item   The level of detail about how the solution works is determined by what
%is appropriate to the type of paper (conference, journal, technical report)

%\item   This section can be fairly short for conference papers, fairly long for
%journal papers, or {\em quite} long in technical reports. It all depends on the
%purpose of the paper and the target audience

%\item   Proposals are necessarily a good deal more vague in this section since
%you have to convince someone you know enough to have a good chance of building
%a solution, but that you have not {\em already} done so.

\textbf{ Campus Factory is the heart of the operation.  It provides all throttling and logic to the submit of glidein jobs to the non-condor cluster.}

\subsection{Campus Factory}
\begin{figure}[ht]
\centering
\scalegraphics{images/FactoryOverview.pdf}
\caption{Overview of Campus Factory function}
\label{fig:campusfactoryoverview}
\end{figure}
The Campus Factory is a daemon that runs on non-condor clusters in order to submit glideins when additional resources are requested.  The Condor instance that the factory communicates with must be on a `gateway' node: Able to talk to both the remote clusters and the local nodes.   The Factory communicates with the \texttt{condor\_collector} daemon in order to detect requests for resources, and the \texttt{condor\_schedd} daemon to submit jobs to the LRM.  

The factory is an integral part of the campus grid because it allows non-condor clusters to participate in the grid.  A Condor cluster would not need the factory.  The factory submits glideins to the Local Resource Manager (LRM), allowing them to run with the priorities set in the LRM.  The jobs, once started, report back to the factory collector as a regular condor pool node.  The factory collector then is able to route jobs from other clusters to these available glideins just as it would for an all-condor cluster.

The Campus Factory is a python daemon that runs as a persistent condor job.  Since it runs as a condor job, the condor daemons will ensure that it stays alive, eliminating the need to monitoring an additional daemon.  The Campus Factory functions are shown in Figure \ref{fig:campusfactoryoverview}.  The factory will periodically query the collector for idle slots, and query the schedd for idle jobs.  The factory will talk to schedds on other clusters listed in the condor configuration variable \texttt{FLOCK\_FROM}.

The factory depends on Condor daemons to carry out many tasks such as:
\begin{itemize}
\item Run and maintain the factory daemon.
\item Submission of the glidein jobs to the LRM (See Section \ref{sec:condorandblahp}).
\item Collect and advertise information on the glidein jobs.
\item Negotiate with submitters in order to route jobs to glideins.
\end{itemize}


\subsubsection{Determining when to submit glideins}
The factory decides whether submit glideins to the underlying non-condor cluster.  The factory has 2 configuration options relating to submission of glideins to the LRM: \texttt{MaxIdleGlideins} and \texttt{MaxQueuedJobs}.

\begin{description}
\item[ \texttt{MaxIdleGlideins}] \hfill \\
An integer representing the number of idle slots that will be allowed before the factory stops submitting jobs. 

\item[ \texttt{MaxQueuedJobs}] \hfill \\
An integer number of queued glideins that will be allowed to be idle in the LRM before submitting more. 

\end{description}

The factory submission logic is as follows:

\begin{algorithm}
\begin{algorithmic}
\IF {idlejobs $<$ MaxIdleGlideins \&\& queuedglideins $<$ MaxQueuedJobs}
	\STATE $toSubmit \gets$ min(MaxIdleGlideins - idlejobs, MaxQueuedJobs - queuedglideins, idleuserjobs)
\ELSE
	\STATE $toSubmit \gets 0$
\ENDIF
\RETURN $toSubmit$

\end{algorithmic}
\caption{Algorithim for determining how many glideins to submit.}
\end{algorithm}

Additionally, the factory has logic to detect glideins that are not reporting to the collector.  This can happen when the the LRM cannot transfer files, if the BLAHP is incorrectly reporting the status of a job, or if there is something wrong with the glideins jobs.

\subsection{Glidein Jobs}
Glidein  \cite{frey2002condor} is a pilot job based grid submission that creates an overlay network.  Glidein is designed to used standard Condor mechanisms to advertise it's availablity to a Condor Collector process, which is queried by the Scheduler to learn about available resources.  Each user job is run in a sandbox on the local disk and is provided with a consistent execution environment across hosts and clusters.  

The factory uses glideins on non-condor resources in order to create a overlay condor cluster that can execute remote jobs via flocking.  The glideins report to a Collector unique to each Cluster and are configured to exit after a configurable amount of time. 

The glidein job requires six condor daemons packaged with a wrapper script.  When the job starts, the Glidein job will:

\begin{enumerate}
\item Create a temporary directory on the local disk.  This will be used for the job sandboxes.
\item Unpackage the glidein executables into the local disk.
\item Set the late binding environment variables for Condor to point to the temporary directory.
\item Start the  \texttt{condor\_master} daemon included in the glidein executables.
\end{enumerate}

The \texttt{condor\_master} will start the \texttt{condor\_startd} which will advertise itself to the glidein collector, therefore making the node available for remote jobs.  

Glideins are being used in production in the Open Science Grid using the software GlideinWMS \cite{sfiligoi2008glideinwms}.  They provide several advantages over regular job submission.  Each glidein sandboxes and monitors the user jobs it runs.  The glidein can run multiple user jobs inside a single Local Resource Management (LRM) job, and will continue to run until the configured time to stop.  Glidein host connects directly with the submitter host, removing the need for staging data.

\subsection{Flocking}
Flocking is enabled between the condor clusters, and the non-condor clusters.  The non-condor clusters run the condor daemons on one node that will handle flocking and submission of glidein jobs.  This node can also serve as the local condor queue for users to submit to. 

\subsection{Condor \& BLAHP}
\label{sec:condorandblahp}
Condor \& BLAHP provides the interface to the local batch system.  It is developed as a part of glite, and is included in the standard condor distribution. 

OfflineAds are used to efficiently match jobs to potential slots on a machine.  These were developed because we do not always want ~5 idle jobs running on a cluster.  We would rather have a few jobs submitted per day, and only submit more glideins if jobs will run there.


\subsection{OfflineAds}
Offline ads are designed to be used for power management. When a node hasn't been matched for a configurable amount of time, the machine can be turned off to save power. When the machine is preparing to turn off, it sends an offline ad to the collector that describes the machine. The OfflineAd includes all of the features that can be used when matching against an online resource.  When the offline ad describing the machine is matched to a job by the Condor negotiator, the negoiator inserts a new attributed into the offline ad called MachineLastMatchTime.  When using power management, the Condor Rooster periodically queries the collector for the offline ads, and wakes the powered off matched nodes to run the job.

The collector maintains the offline ads for a configurable amount of time using the configuration variable OFFLINE\_EXPIRE\_ADS\_AFTER. During this time, the condor negotiator will treat the offline ad just as it would a real ad and match it to idle jobs. Since the Negotiator sees no difference between running and offline ads, the offline ads will be matched even when flocking from another condor pool.  This is how the offline ads are used in the campus factory.

\subsubsection{Creating OfflineAds}
The factory detects classads of running glideins, copies the classads, and re-advertises them as offline ads. Since the offline ad is an exact copy of a running glidein, it is reasonably expected that you can get a similar glidein when you submit to the local scheduler.

To change a glidein classad into a offline ad, the following attributes must be changed

\begin{itemize}
\item Offline = true
\item Name - to a unique name
\item MyCurrentTime = LastHeardFrom - Time now
\item ClassAdLifetime - To address a bug in the handling of offline ads by Condor. This is how many seconds the collector will keep this ad
\item State = Unclaimed - Make sure it will match with idle jobs.
\item Activity = Idle - Again, for matching 
\end{itemize}

Convenience attributes: 
\begin{itemize}
\item PreviousName - Value of 'Name' attribute of the original ad. Useful for debugging. 
\end{itemize}

\subsubsection{Managing OfflineAds}
By default, the factory will attempt to maintain a specific number of offline ads. This can be done in a number of ways, such as always maintaining the newest 10 ads. Or you can sort by different 'types' of machines (big memory, big disk), and keep an assortment of unique ads.  Currently, the factory only keeps the latest 10 ads.

To maintain the classads, the factory queries the collector for offline ads. If it detects more than 10, it will only keep the newest 10. If less then ten, the offline ad manager will list the site as Delinquent, and will recommend submitting more glideins.

\subsubsection{Influence OfflineAds have on the Factory}
The OfflineAds do not completely replace all logic relating to the factory. The site must still meet the idle glideins/idle slots requirements that were originally used to throttle new glideins. The OfflineAds do replace the need for the factory to query remote schedd's to for idle jobs. The negotiator and collector take care of all job matching with semi-accurate glidein classads.

The logic of the factory follows:

\begin{enumerate}
\item Are there idle startd's?
\item Are there idle glideins in queue?
\item Have any of the idle offline ads matched in the last x seconds?
\item If we get this far, submit some glideins. 
\end{enumerate}


\section{Evaluation}
\label{sec:Evaluation}

\subsubsection*{Social political stuff}

\subsubsection*{How we tested our solution}
\begin{itemize}
%\item   Performance metrics 
%\item   Performance parameters
%\item   Experimental design

\item Production jobs on Firefly

\end{itemize}


\subsubsection*{How our solution performed, how its performance compared to
that of other solutions mentioned in related work, and how these results show
that our solution is effective}

\begin{itemize}
%\item   Presentation and Interpretation
%\item   Why, how, and to what degree our solution is better
%\item   Why the reader should be impressed with our solution
%\item   Comments

\item
Faster job submission and start than globus.  Should be easy to show.

\item
Run at other campuses.

\item
Submit jobs between campuses.

\end{itemize}


\subsubsection*{Context and limitations of our solution as required for 
summation}
\begin{itemize}
%\item   What the results {\em do} and {\em do not} say
\item
Therefore, my solution is awesome.

\end{itemize}



\section{Conclusions and Future Work}
\label{sec:Conclusion}

\subsubsection*{The problem we have solved}
\begin{itemize}

%\item   The most succinct statement of the problem in the paper. Ideally one
%sentence. More realistically two or three. Remember that you simply state it
%without argument. If you have written a good paper you are simply reminding the
%reader of what they now believe and of how much they agree with you.

\item
The framework that I have described here creates a grid of clusters that can overflow to each other, and out to the other grids such as the Open Science Grid, or other campuses.  

\end{itemize}



\subsubsection*{Our solution to the problem}
\begin{itemize}

%\item    
%Again, the succinct statement that you have presented a solution

%\item   Sometimes it works well to leave it at that and not even describe your
%solution here. If you do, then again state your solution in one or two
%sentences taking the rhetorical stance that this is all obvious. If you have a
%good solution and have written an effective paper, then the reader already
%agrees with you.

\item
Combination of Condor, Glidein, and BLAHP.

\end{itemize}



\subsubsection*{Why our solution is worthwhile in some significant way}
\begin{itemize}

%\item   
%Again, a succinct restatement in just a few sentences of why your solution is
%worthwhile assuming the reader already agrees with you

\item
This solution keeps the administrator in control of priorities and access policies.  It can also follow the campus' security model.

\end{itemize}



%Why the reader should be impressed and/or pleased to have read the paper
\begin{itemize}

%\item   A few sentences about why your solution is valuable, and thus why the
%reader should be glad to have read the paper and why they should be glad you
%did this work.

\item
Provides a cookie cutter, well packaged solution for campuses to deploy a campus grid.

\end{itemize}



\subsubsection*{What we will (or could) do next}
\begin{itemize}
%\item   Improve our solution
%\item   Apply our solution to harder or more realistic versions of this problem
%\item   Apply our solution or a related solution to a related problem

\item 
Scale this solution to other universities and institutions.  Already doing this with the OSG Campus Grid Initiative.

\end{itemize}




\bibliographystyle{plain}
\bibliography{DerekWeitzelThesis}



\end{document}
